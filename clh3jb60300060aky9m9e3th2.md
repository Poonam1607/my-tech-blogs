---
title: "Kubernetes Project : Micro-Services on Kubeadm"
datePublished: Sun Apr 30 2023 14:56:17 GMT+0000 (Coordinated Universal Time)
cuid: clh3jb60300060aky9m9e3th2
slug: kubernetes-project-micro-services-on-kubeadm
cover: https://cdn.hashnode.com/res/hashnode/image/upload/v1682866398508/264677db-1549-4a93-ab6f-ad036bbe025e.png
ogImage: https://cdn.hashnode.com/res/hashnode/image/upload/v1682866545013/2c5f6a1b-1682-4223-a9f0-2f5604fbebff.png
tags: kubernetes, troubleshooting, trainwithshubham, kubeweek, kubeweekchallenge

---

## Introductionüßë‚Äçü¶Ø

Everything till now we have done in our local machine. we have gained knowledge on how to deploy pods and nodes, create master nodes and worker nodes, and create services and secrets using volumes and claims. Now this is the time I was awaiting‚è≥ (and you too), to do all these things outside the local system.

In this blog, we will be doing a hands-on projectüßë‚Äçüíª in which we will Set up and **Deploy** **Microservices** on Kubernetes Cluster using **kubeadm** and Expose them to **Postman** with Integration of **Persistent** Volumes and **MongoDB** and **troubleshooting**.

We will be usingüëá

* python **flask** micro-services,
    
* **mongo db** for the database,
    
* **kubeadm** for cluster creation, and
    
* **Postman** for accessing the application using persistent **volume** **claims,** we will be deploying an instance of mongo db and
    

a lot of **troubleshooting**!üòµ‚Äçüí´

**Project**: A simple **task manager** application. You can use the project or use our own. Your choice!

**Github** link: [https://github.com/LondheShubham153/microservices-k8s](https://github.com/LondheShubham153/microservices-k8s)

## Setup Kubernetes **Cluster** using `Kubeadm`

1. First, you need an account in **AWS** to create **instances**
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682828077596/e4f1fe1c-b697-4842-a8d8-eb2f32b43cb0.png align="center")
    
    Now, on the search bar, type **instances** and select **EC2** and then select on **Launch** **Instance** button.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682828276243/1c95d793-493d-4724-86ff-b428bbd89cec.png align="center")
    
    Give the name at your convenience.
    
    * I am giving it `kubernetes-master`
        
    * Select the number of `instances=2`
        
    * Select the `Ubuntu` machine
        
    * Select `t2.medium` as an Instance type because in the free tier, only `1cpu` is available and here we want 2 nodes set up, **master** and **worker**.
        
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682828531965/ee948ed9-a177-49e4-981e-513526e024d7.png align="center")
    
    * Now select a `key-pair` if you have already. If not then create new pair as I have done.
        
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682828452351/5d83470d-8083-4e4f-a2c0-9c2852a60dc1.png align="center")
    
    Now select on launch instance until it's running and passed the checks. And change the name of the 2nd instance as `kubernetes-worker`
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682830960660/9e7ff2c8-5581-4cfa-989c-fa0880c180cf.png align="center")
    

* Now it's time to **connect** these **instances** to your local machine.
    
* Check the `kubernetes-master` box and then click on connect button and then copy the ssh key
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682832299899/f518e93b-af40-4631-ac53-0f9d9d205a6f.png align="center")
    
* Now open up your terminal and go inside the directory where you have downloaded that generated `key-pair` `.pem` file.
    
* Run the command `sudo <ssh-key>` on both sides with their own key.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682838461730/e055a2fb-bfc7-4a25-b80f-f8bea18ffeb8.png align="center")
    
* Now we have to **install** `kubeadm`, `kubectl` and `kubelet` in both the **master** & **worker** node. And before this, make sure you are inside that directory
    
* In this **Github**, you will find all the commands you have to follow in order to install: [https://github.com/RishikeshOps/Scripts/blob/main/k8sss.sh](https://github.com/RishikeshOps/Scripts/blob/main/k8sss.sh)
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682838259390/56d3e28d-287e-42b8-a614-2ee79ed5348b.png align="center")
    
    Open the terminal side by side for the master node and another for the worker node for convenience. And in the URL, paste the commands according to that.
    
* ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682838523225/a0efb4de-7251-4d0f-90d6-ce566b8dfce2.png align="center")
    
    Now in the master node, run:
    
* ```bash
                sudo su
                kubeadm init
    ```
    
    Then **export** it and then run the `kubectl apply -f` command.
    
    [https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml](https://github.com/weaveworks/weave/releases/download/v2.8.1/weave-daemonset-k8s.yaml)
    
* ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682839329879/487f4808-e664-448a-b38e-b47b464dc425.png align="center")
    
* Now run the same command `sudo su` in the worker node and run:
    
* ```bash
                sudo su
                kubeadm reset pre-flight checks
    ```
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682839431334/c2730345-1f16-4fa7-bec5-61995d9298c0.png align="center")
    
    Now **join** the `worker-node` to the `master-node` by running the generated **token** in the master node:
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682839776798/e2f052f9-48e8-4d5d-985d-2d16d45fb455.png align="center")
    
    If you see the token carefully, it is listening to `port:6443` so we have to add in the instance.
    
* Click on the `master-node` then go to **security** and click on **edit inbound rules.**
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682840007654/3d2f35d3-5280-49ba-995a-cbb00510065e.png align="center")
    
    Now add the port to it
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682840196696/31c1ade4-4ea6-47f4-ad7c-573e9456b6f3.png align="center")
    
    Now see the worker node terminal. It has joined the cluster.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682840245304/75a3cb9a-a29a-437b-90b3-afe4d16d333a.png align="center")
    
    Now you can check the `nodes`
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682840293501/7b43a5d9-e38f-4320-b526-90484949a0f3.png align="center")
    

## Deploy the Taskmaster Micro-servicesü•∏

* Now `clone` the **GitHub** project which I have shared the link already above.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682852505860/780057f1-be9c-4083-965d-2f7bce4c0872.png align="center")
    
    Now you can the `nodes` and `pods` that are running.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682840431989/7c9db395-c9e0-4f3f-8e24-3e019d409684.png align="center")
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682840469101/5442986e-64f9-437f-9222-2da291069858.png align="center")
    
    The left one is the `master-node` and the right is the `worker-node`. You can see running pods on both sides.
    
* Now, there is only a `pod` running. Let's scale this up to three using the `--scale` command.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682840579995/244e3dcb-bf58-4abb-a56f-cefb4eef6932.png align="center")
    
    Now the three `pods` are **up** and **running**.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682840656441/2b88e650-98d4-4aed-b218-87a49e0b26cc.png align="center")
    
    Let's **deploy** the `service` now. Check the `taskmaster-svc.yml` file.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682841168170/0bd0f6ee-4e6f-4ab6-9bc7-c00477f8df4f.png align="center")
    
    Now, run the `kubectl apply` command:
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682841195681/7873f32c-4929-4d00-97d5-3691e573a1d3.png align="center")
    
    Check the `service` created by you so that we can access our application.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682841268429/d45c4a8e-36ea-4a12-a6a2-3a8d56cf1afe.png align="center")
    
    `30007` is the `port` in which our application is running.
    
* Now again, we have to add this port t our **aws console** `master node` **instance.**
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682841589959/27f40e3f-ec4f-4cf7-a98b-61d21f7c61b3.png align="center")
    
    Now click on the `worker-node` and copy its IP address.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682841799545/4da41119-3fe6-47c0-a0ba-111d9f94a652.png align="center")
    

## Exposes the Service to Postmanüßë‚Äç‚úàÔ∏èüì•

* Now paste this URL into the `health check cluster` with `port:30007` and send the requests.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682841923527/fe5c5d5f-c4e4-49ab-85c7-686f00c260f0.png align="center")
    
    As you can see our application is running now.
    

1. Integrate Persistent Volumes & Persistent Volume Clain
    

* Now we will create **persistent volume**. It has a `mongo-pv.yml` file in it. We just have to do `kubectl apply -f <file-name>` command:
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682851629970/89d20bcc-66c9-4cba-bbb0-104a82493178.png align="center")
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682851653306/cd711a7a-9c34-4853-8069-fec7ea1481e7.png align="center")
    
    Let's see the created **volumes** by using the `get` command:
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682851725009/7163db4a-bf2b-422b-aec0-bfc48831c118.png align="center")
    
    As you can see above, the volume is available for us but nobody has claimed it yet. So now we will create the **persistent volume claim.**
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682851816854/d5823eff-094d-46fd-9385-169fee24297c.png align="center")
    
    Now again, run the same command to see the created **volumes**
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682851873157/a021b407-3764-4cd4-8c00-8147ac829bce.png align="center")
    
    This time you can see, the storage is claimed now and bounded
    

## Deploy Mongo DBüõó

* Now let's see the `mongo.yml` file.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682851939737/520bab24-eaf1-49b2-aa02-7da3fd57a890.png align="center")
    
    We will **deploy** this file to create the deployment of `mongo db`
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682852001952/82a02688-c689-47c9-9030-766cb097c9f4.png align="center")
    
    We have created everything we want. Now let's see the running **pods** on both nodes.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682852066535/389156fc-928d-4a47-ad9a-ddb8a1daf23e.png align="center")
    

## Integrate Micro-ServicesüïµÔ∏è

* Let's create the `service` for the `mongo.yml` file. It has already been coded in `mongo-svc.yml` :
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682852189521/06872ba2-9060-4eec-9ba4-2bde833984c2.png align="center")
    
    Run the `apply` command to implement the above file. And `get` the command to see the **IPs** and **Ports**
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682852231360/227482d5-7d35-4722-b1f6-48191fe21c2c.png align="center")
    
    This application is a task manager in which we can also add more tasks to it and it must be running.
    
* So let's see to run the same URL for the `/tasks` section.
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682856764996/ae3534f9-5e24-4623-a6cc-25203f64b1a0.png align="center")
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682856787041/8b9edb64-5173-444e-a4bc-82767cd6841d.png align="center")
    
    So basically, I don't know what just happened.
    

## Troubleshootingü§ï

Today's challenge is all about making a project available and the challenges we faced in doing so and coming over from it.

As we all are doing a **7-day Kubernetes challenge** together, we know there are topics for daily to perform. And today we have to perform with **AWS**, **kubeadm**, **Postman** etc.

The **problems** I have faced doing this project are listed below:üëá

1. **AWS Sign-up** -
    
    * This is my first time doing hands-on in aws. So I don't have any account on it.
        
    * Today early morning I started with doing sign-up. The registration process takes time as it will demand credit/debit card credentials.
        
    * I submitted the credentials but for no reason, it was unable to take my card credentials. May be bank side issue I don't know. So I waited for a while and tried again after an hour and I signed up.
        
    * After signing up the Instances section is not showing, it's saying It may take up to 24 hours to start your account.
        
    * For a moment I thought today I will not make it happen. Then after some time, I tried again and then it worked.
        
    * So it took me almost 2hours to sign-up for aws.
        
2. **Correct Directory**: When I was generating the keys while creating the instances. The first thing we need to do on entering the terminal is to go inside the directory where the `.pem` file was downloaded. And I forgot that. And doing `sudo ssh` in the `root` directory.
    
    Then I asked for help from one of the folk then I got my issue resolved. I changed my directory then everything start working.
    
3. **Network Connectivity** - I was doing this whole thing with learning and doing alongside. And suddenly I got this error message:
    
    ![](https://cdn.hashnode.com/res/hashnode/image/upload/v1682861211655/66926f0d-7a9c-43e9-8a0b-01781cbe3d16.png align="center")
    
    And without trying to resolve this, I did the whole procedure from creating instances to installing everything, did all the deployments again then continued further where I left off.
    
4. **Postman API** - I have never worked on Postman so I don't even know the purpose of using it. It took me a lot of time to get started with this service. I watched several youtube videos to understand how it works. Because we need to create **GET**, **PUT** and **POST** `method` requests for the application to run.
    
5. **TimoutError** - The last error where we stopped, I am still figuring out how to solve that for very long. And I will do that.
    

## Take Aways from My Troubleshootingüéí

1. If you are doing any challenge like me or preparing for it. Must sign-up early for an **AWS** account because not for everyone but it might take a day to start your account as it says. ***So better early than late.ü§ì***
    
2. Always follow the steps mentioned already for installation and recheck every step as it can cause you to do the whole process again. And that's very frustrating.üòñ
    
3. A stable internet connection. I know it sounds very childish in a takeaway section, but trust me if you are not in a stable connection it will kill you. And I am *dead* now.ü´†
    
4. To do projects like this, you must know each and every aspect of it. You must learn firsts and then apply. It will give you a good understanding and the better results.
    
5. Now, talking about the last **timeouterror,** I am solving the issue and will update this blog soon. Just holding this up for the sake of completing today's challeneg as it is the last day. So if you are reading this in the present tense then let's do it together‚úä and comment on your solution, we can discuss it. And if you are reading this in the future then, Nothing. Everything is fine and updated.üòÑ
    

## My learnings from this challengeüßë‚Äçüéì

* I am learning Kubernetes for a while. But in my learning I was not doing it practically, only learning concepts and moving further without implementing anythingü§ê. And this challenge changed my way of learning completely. As daily I learned a new topic and implemented it immediatelyü§Ø.
    
* I have never done this type of challenge before. It trained me how to push myself to learn new things daily‚ôø. And I have never done that. So that's a big achievement for me!ü§ì
    
* I learned architecture before but never get into depth but this time for the sake of writing blogs I deep dive into the architectures of Kubernetes.
    
* I learned how to work with AWS and Postman API.
    
* I learned how to create an instance and connect it to the local environment and many such things.
    

## Closing Noteüìú

As this is the last of the **7-day** series I have mixed feelings. I am relaxed but also quite unhappy because I am a procrastinator and this daily challenge has encouraged me to learn a new topic daily. And this was a big advantage of this challenge.

**A message for you!‚úçÔ∏è**

*Don't give up if you lack somewhere behind. If you didn't complete any one of the daily tasks, no worries! It's okküôÇ, everyone has their own pace of learning. This 7-day series is not a raceüêÄ where you have to come first and win the prize.*

*If you didn't complete today's challenge it doesn't mean you are out of winning. A winner is the one who managed to learn daily in this series. I****f you have learned something new in these 7 days, you are the winner. Good Job!üëè***

I am thankful to @[Shubham Londhe](@TrainWithShubham) sir for organizing this amazing **7-day Kubernetes challengeüî•** for the community. This week went amazing with super learnings. Hoping for more such challenges from youüôå.

---

Thank you all of you for being with me on this 7-day journeyüñ§.

Happy learnings!üßë‚Äçüíª